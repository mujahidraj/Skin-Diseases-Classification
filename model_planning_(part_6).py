# -*- coding: utf-8 -*-
"""Model Planning (Part-6).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RQPueqP-n9ubAy3SuLdwG0FywFr7zXHt
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import shutil
from tqdm import tqdm

# Path to your dataset on Google Drive
drive_dataset_path = "/content/drive/MyDrive/Thesis/Split_Dataset"
# Path where you want to copy locally (Colab's fast storage)
local_dataset_path = "/content/dataset/Split_Dataset"

# Remove any old copy if exists
if os.path.exists(local_dataset_path):
    shutil.rmtree(local_dataset_path)

# Copy dataset from Drive to Colab local storage
print("Copying dataset from Drive to local storage...")
shutil.copytree(drive_dataset_path, local_dataset_path)

print("✅ Dataset copied to:", local_dataset_path)

# This command removes the TensorFlow Hub cache directory
!rm -rf /tmp/tfhub_modules

"""**convNeXt**"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from tensorflow.keras.applications import ConvNeXtTiny
import matplotlib.pyplot as plt
import os
import numpy as np
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
import cv2

# --- 1. SETUP & CONFIGURATION ---
base_dir = '/content/dataset/Split_Dataset'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')
test_dir = os.path.join(base_dir, 'test')

IMG_SIZE = 224
BATCH_SIZE = 64
INITIAL_EPOCHS = 5
FINE_TUNE_EPOCHS = 15
TOTAL_EPOCHS = INITIAL_EPOCHS + FINE_TUNE_EPOCHS
MODEL_SAVE_PATH = "best_convnext_model.keras"

# --- 2. DATA PIPELINE ---
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest',
    preprocessing_function=tf.keras.applications.convnext.preprocess_input
)
validation_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.convnext.preprocess_input)
test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.convnext.preprocess_input)

train_generator = train_datagen.flow_from_directory(
    train_dir, target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode='sparse')
validation_generator = validation_datagen.flow_from_directory(
    validation_dir, target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode='sparse')
test_generator = test_datagen.flow_from_directory(
    test_dir, target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, class_mode='sparse', shuffle=False)

num_classes = train_generator.num_classes
print(f"\nFound {num_classes} classes.")

# --- 3. BUILDING THE ConvNeXt MODEL ---

def create_convnext_model(num_classes):
    convnext_base = ConvNeXtTiny(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))
    convnext_base.trainable = False

    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    # Pass the inputs through the base model, which is now treated as a single layer
    x = convnext_base(inputs, training=False) # Use training=False when layers are frozen
    x = GlobalAveragePooling2D()(x)
    x = Dropout(0.5)(x)
    outputs = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs=inputs, outputs=outputs)
    # ⭐️ THE FIX: Return the base model layer along with the full model
    return model, convnext_base

# ⭐️ THE FIX: Capture both the full model and the base model layer
model, convnext_base_layer = create_convnext_model(num_classes)
model.summary()

# --- 4. TRAINING & FINE-TUNING ---
checkpoint_cb = ModelCheckpoint(MODEL_SAVE_PATH, save_best_only=True, monitor='val_accuracy', mode='max')
early_stopping_cb = EarlyStopping(patience=5, monitor='val_accuracy', mode='max', restore_best_weights=True)

print("\n--- Starting Initial Training (Classifier Head Only) ---")
model.compile(optimizer=Adam(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history = model.fit(
    train_generator,
    epochs=INITIAL_EPOCHS,
    validation_data=validation_generator,
    callbacks=[checkpoint_cb, early_stopping_cb]
)

print("\n--- Starting Fine-Tuning (Full Model) ---")
# ⭐️ THE FIX: Use the direct reference to the base layer to unfreeze it
convnext_base_layer.trainable = True
model.compile(optimizer=Adam(learning_rate=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history_fine = model.fit(
    train_generator,
    epochs=TOTAL_EPOCHS,
    initial_epoch=history.epoch[-1],
    validation_data=validation_generator,
    callbacks=[checkpoint_cb, early_stopping_cb]
)

# --- 5. PLOTTING TRAINING HISTORY ---
# (Plotting code remains the same)
print("\n--- Plotting Training and Validation History ---")
acc = history.history['accuracy'] + (history_fine.history.get('accuracy', []))
val_acc = history.history['val_accuracy'] + (history_fine.history.get('val_accuracy', []))
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.axvline(len(history.epoch) -1, color='gray', linestyle='--', label='Start Fine-Tuning')
plt.title('ConvNeXt Model Accuracy'); plt.legend(); plt.grid(True)
# Add similar plotting for loss
loss = history.history['loss'] + (history_fine.history.get('loss', []))
val_loss = history.history['val_loss'] + (history_fine.history.get('val_loss', []))
plt.subplot(1, 2, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.axvline(len(history.epoch) - 1, color='gray', linestyle='--', label='Start Fine-Tuning')
plt.title('ConvNeXt Model Loss'); plt.legend(); plt.grid(True)
plt.tight_layout(); plt.show()


# --- 6. FINAL EVALUATION ON TEST SET ---
print("\n\n--- Loading best model and starting Final Evaluation on Test Data ---")
best_model = tf.keras.models.load_model(MODEL_SAVE_PATH)
test_loss, test_accuracy = best_model.evaluate(test_generator)
print(f"\nOverall Test Accuracy (from best model): {test_accuracy*100:.2f}%")

y_pred_probs = best_model.predict(test_generator)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = test_generator.classes

class_indices = train_generator.class_indices
sorted_indices = sorted(class_indices.items(), key=lambda item: item[1])
class_names = [item[0] for item in sorted_indices]

print("\n## Classification Report ##\n")
print(classification_report(y_true, y_pred, target_names=class_names))

print("\n## Confusion Matrix ##\n")
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.title('ConvNeXt Confusion Matrix (Best Model)'); plt.ylabel('True Label'); plt.xlabel('Predicted Label')
plt.show()

# --- 7. XAI - GRAD-CAM ANALYSIS ---
print("\n\n--- Starting XAI Analysis (Grad-CAM) on the Best Model ---")
IMAGE_PATH = '/content/dataset/Split_Dataset/test/Nail_psoriasis/3227__ProtectWyJQcm90ZWN0Il0_FocusFillWzI5NCwyMjIsInkiLDM2XQ.jpeg' # <-- CHANGE THIS
os.makedirs("xai_results_convnext", exist_ok=True)

# Grad-CAM function (remains the same)
def get_grad_cam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])
    with tf.GradientTape() as tape:
        last_conv_layer_output, preds = grad_model(img_array)
        if pred_index is None: pred_index = tf.argmax(preds[0])
        class_channel = preds[:, pred_index]
    grads = tape.gradient(class_channel, last_conv_layer_output)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    heatmap = (last_conv_layer_output[0] @ pooled_grads[..., tf.newaxis])
    heatmap = tf.squeeze(heatmap)
    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-8)
    return heatmap.numpy()

def superimpose_grad_cam(img, heatmap, alpha=0.4):
    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
    heatmap = np.uint8(255 * heatmap)
    jet = plt.get_cmap("jet")
    jet_colors = jet(np.arange(256))[:, :3]
    jet_heatmap = jet_colors[heatmap]
    jet_heatmap = np.uint8(255 * jet_heatmap)
    jet_heatmap = cv2.cvtColor(jet_heatmap, cv2.COLOR_RGB2BGR)
    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    superimposed_img_bgr = cv2.addWeighted(img_bgr, 1 - alpha, jet_heatmap, alpha, 0)
    superimposed_img_rgb = cv2.cvtColor(superimposed_img_bgr, cv2.COLOR_BGR2RGB)
    return superimposed_img_rgb

original_img_rgb = cv2.imread(IMAGE_PATH)
original_img_rgb = cv2.cvtColor(original_img_rgb, cv2.COLOR_BGR2RGB)
xai_img_array = tf.keras.utils.load_img(IMAGE_PATH, target_size=(IMG_SIZE, IMG_SIZE))
xai_img_array = tf.keras.utils.img_to_array(xai_img_array)
xai_img_array = np.expand_dims(xai_img_array, axis=0)
preprocessed_xai_img = tf.keras.applications.convnext.preprocess_input(xai_img_array)

xai_preds = best_model.predict(preprocessed_xai_img)
xai_pred_index = np.argmax(xai_preds[0])
print(f"XAI Image Model Prediction: {class_names[xai_pred_index]} with {xai_preds[0][xai_pred_index]:.2f} confidence.")

# ⭐️ THE FIX: Use the name from the direct reference to get the layer from the loaded model
loaded_convnext_base_layer = best_model.get_layer(convnext_base_layer.name)

# Dynamically find the last conv-like layer for Grad-CAM
def find_last_conv_layer(model_base):
    for layer in reversed(model_base.layers):
        if len(layer.output_shape) == 4 and 'conv' in layer.name:
            return layer.name
    return None

actual_last_conv_layer_name = find_last_conv_layer(loaded_convnext_base_layer)

if actual_last_conv_layer_name:
    full_layer_name = f"{loaded_convnext_base_layer.name}/{actual_last_conv_layer_name}"
    print(f"Using '{full_layer_name}' as the last convolutional layer for Grad-CAM.")
    heatmap = get_grad_cam_heatmap(preprocessed_xai_img, best_model, full_layer_name, pred_index=xai_pred_index)
    superimposed_image = superimpose_grad_cam(original_img_rgb, heatmap)
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(original_img_rgb); plt.title("Original Image"); plt.axis('off')
    plt.subplot(1, 2, 2)
    plt.imshow(superimposed_image); plt.title("ConvNeXt Grad-CAM"); plt.axis('off')
    plt.tight_layout(); plt.show()
    save_path = os.path.join("xai_results_convnext", f"grad_cam_{os.path.basename(IMAGE_PATH)}")
    plt.imsave(save_path, superimposed_image)
    print(f"\n--- XAI analysis complete. Grad-CAM image saved to '{save_path}' ---")
else:
    print("Could not find a suitable last convolutional layer for Grad-CAM.")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt
import cv2 # OpenCV for image processing
import os

# --- 1. CONFIGURATION ---

MODEL_SAVE_PATH = "best_convnext_model.keras"
IMAGE_PATH = '/content/dataset/Split_Dataset/test/Nail_psoriasis/3227__ProtectWyJQcm90ZWN0Il0_FocusFillWzI5NCwyMjIsInkiLDM2XQ.jpeg' # <-- CHANGE THIS
TEST_DIR = '/content/dataset/Split_Dataset/test'
IMG_SIZE = 224
os.makedirs("xai_results_convnext", exist_ok=True)


# --- 2. THE GRAD-CAM ALGORITHM ---

# This function remains the same
def superimpose_grad_cam(img, heatmap, alpha=0.4):
    """Superimposes the heatmap on the original image."""
    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
    heatmap = np.uint8(255 * heatmap)
    jet = plt.get_cmap("jet")
    jet_colors = jet(np.arange(256))[:, :3]
    jet_heatmap = jet_colors[heatmap]
    jet_heatmap = np.uint8(255 * jet_heatmap)
    jet_heatmap = cv2.cvtColor(jet_heatmap, cv2.COLOR_RGB2BGR)
    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    superimposed_img_bgr = cv2.addWeighted(img_bgr, 1 - alpha, jet_heatmap, alpha, 0)
    superimposed_img_rgb = cv2.cvtColor(superimposed_img_bgr, cv2.COLOR_BGR2RGB)
    return superimposed_img_rgb

# --- 3. LOAD MODEL AND PREPARE DATA ---

print(f"--- Loading the best trained model from: {MODEL_SAVE_PATH} ---")
best_model = tf.keras.models.load_model(MODEL_SAVE_PATH)

temp_datagen = ImageDataGenerator()
temp_generator = temp_datagen.flow_from_directory(directory=TEST_DIR, shuffle=False)
class_indices = temp_generator.class_indices
sorted_indices = sorted(class_indices.items(), key=lambda item: item[1])
class_names = [item[0] for item in sorted_indices]
print("Class names found and ordered:", class_names)

original_img_rgb = cv2.imread(IMAGE_PATH)
original_img_rgb = cv2.cvtColor(original_img_rgb, cv2.COLOR_BGR2RGB)

xai_img_array = tf.keras.utils.load_img(IMAGE_PATH, target_size=(IMG_SIZE, IMG_SIZE))
xai_img_array = tf.keras.utils.img_to_array(xai_img_array)
xai_img_array = np.expand_dims(xai_img_array, axis=0)
preprocessed_xai_img = tf.keras.applications.convnext.preprocess_input(xai_img_array)

xai_preds = best_model.predict(preprocessed_xai_img)
xai_pred_index = np.argmax(xai_preds[0])
print(f"\nXAI Image Model Prediction: '{class_names[xai_pred_index]}' with {xai_preds[0][xai_pred_index]:.2f} confidence.")

# --- 4. ⭐️ THE FIX: Robust Grad-CAM Generation ---

# Find the ConvNeXt base model layer
convnext_base_layer = None
for layer in best_model.layers:
    if isinstance(layer, tf.keras.Model) and 'convnext' in layer.name:
        convnext_base_layer = layer
        break
if convnext_base_layer is None:
    raise ValueError("Could not find the ConvNeXt base layer in the loaded model.")

# Find the name of the last conv-like layer
def find_last_conv_layer_name(model_base):
    for layer in reversed(model_base.layers):
        if hasattr(layer, 'output_shape') and len(layer.output_shape) == 4 and ('conv' in layer.name or 'dense' in layer.name):
            return layer.name
    return None

last_conv_layer_name = find_last_conv_layer_name(convnext_base_layer)

if last_conv_layer_name:
    # Create a sub-model that outputs the feature map of the target layer
    last_conv_layer = convnext_base_layer.get_layer(last_conv_layer_name)
    feature_extractor = tf.keras.Model(convnext_base_layer.inputs, last_conv_layer.output)

    # Use GradientTape on the full model to get the gradients
    with tf.GradientTape() as tape:
        # Pass the preprocessed image through the base model part to get feature maps
        feature_maps = feature_extractor(preprocessed_xai_img)
        # We need to tell the tape to "watch" these feature maps
        tape.watch(feature_maps)
        # Pass the feature maps through the rest of the model to get the final prediction
        # Get the layers that come after the base model
        head_layers = best_model.layers[2:] # Skips input and base model
        head_output = feature_maps
        for layer in head_layers:
            head_output = layer(head_output)

        # Get the specific class prediction
        class_channel = head_output[:, xai_pred_index]

    # Get the gradient of the class prediction with respect to the feature maps
    grads = tape.gradient(class_channel, feature_maps)

    # Compute the heatmap (same logic as before)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    feature_maps = feature_maps[0]
    heatmap = feature_maps @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + tf.keras.backend.epsilon())
    heatmap = heatmap.numpy()

    # Display and save the result
    superimposed_image = superimpose_grad_cam(original_img_rgb, heatmap)
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1); plt.imshow(original_img_rgb); plt.title("Original Image"); plt.axis('off')
    plt.subplot(1, 2, 2); plt.imshow(superimposed_image); plt.title("ConvNeXt Grad-CAM"); plt.axis('off')
    plt.tight_layout(); plt.show()
    save_path = os.path.join("xai_results_convnext", f"grad_cam_{os.path.basename(IMAGE_PATH)}")
    plt.imsave(save_path, superimposed_image)
    print(f"\n--- XAI analysis complete. Grad-CAM image saved to '{save_path}' ---")

else:
    print("Could not find a suitable last convolutional layer for Grad-CAM.")